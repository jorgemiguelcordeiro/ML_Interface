{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Análise Avançada do Mercado de Trabalho em Portugal\n",
    "\n",
    "Este notebook realiza uma análise completa das ofertas de emprego usando modelos da Hugging Face e técnicas avançadas de NLP.\n",
    "\n",
    "## 📊 Funcionalidades:\n",
    "- Extração inteligente de skills usando NER\n",
    "- Classificação automática de tipos de emprego\n",
    "- Análise de sentimento das ofertas\n",
    "- Topic modeling para descobrir tendências\n",
    "- Clustering de skills similares\n",
    "- Visualizações interativas\n",
    "- Recomendações personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de dependências (execute apenas uma vez)\n",
    "!pip install transformers torch pandas numpy matplotlib seaborn plotly wordcloud\n",
    "!pip install scikit-learn networkx sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from job_analyzer import JobAnalyzer\n",
    "from visualization_engine import VisualizationEngine\n",
    "from trend_analyzer import TrendAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✅ Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 1. Inicialização e Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o analisador\n",
    "print(\"🔄 Inicializando JobAnalyzer...\")\n",
    "analyzer = JobAnalyzer('expresso_empregos + pequeno.csv')\n",
    "\n",
    "print(f\"📊 Dados carregados: {len(analyzer.df)} ofertas de emprego\")\n",
    "print(f\"📅 Período: {analyzer.df['post_date'].min()} a {analyzer.df['post_date'].max()}\")\n",
    "\n",
    "# Visualizar amostra dos dados\n",
    "print(\"\\n🔍 Amostra dos dados:\")\n",
    "analyzer.df[['title', 'location', 'recruiter']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 2. Preprocessamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar e preprocessar dados\n",
    "print(\"🧹 Executando preprocessamento...\")\n",
    "processed_data = analyzer.clean_and_preprocess()\n",
    "\n",
    "print(f\"✅ Preprocessamento concluído!\")\n",
    "print(f\"📊 Dados finais: {len(processed_data)} ofertas\")\n",
    "print(f\"📝 Média de palavras por oferta: {processed_data['word_count'].mean():.0f}\")\n",
    "print(f\"📏 Média de caracteres por oferta: {processed_data['text_length'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 3. Extração de Skills com Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair skills usando modelos HF\n",
    "print(\"🎯 Extraindo skills com modelos da Hugging Face...\")\n",
    "skills_by_job = analyzer.extract_skills_with_hf()\n",
    "\n",
    "# Estatísticas das skills\n",
    "total_skills = len(analyzer.all_skills)\n",
    "unique_skills = len(set(analyzer.all_skills))\n",
    "avg_skills_per_job = np.mean([len(skills) for skills in skills_by_job.values()])\n",
    "\n",
    "print(f\"✅ Extração concluída!\")\n",
    "print(f\"🔍 Total de skills encontradas: {total_skills}\")\n",
    "print(f\"🎯 Skills únicas: {unique_skills}\")\n",
    "print(f\"📊 Média de skills por oferta: {avg_skills_per_job:.1f}\")\n",
    "\n",
    "# Top 15 skills mais procuradas\n",
    "from collections import Counter\n",
    "skill_counts = Counter(analyzer.all_skills)\n",
    "print(\"\\n🏆 Top 15 Skills Mais Procuradas:\")\n",
    "for i, (skill, count) in enumerate(skill_counts.most_common(15), 1):\n",
    "    print(f\"{i:2d}. {skill:<25} ({count} menções)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏢 4. Classificação de Tipos de Emprego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificar tipos de emprego\n",
    "print(\"🏢 Classificando tipos de emprego...\")\n",
    "job_categories = analyzer.classify_job_types_with_hf()\n",
    "\n",
    "# Estatísticas das categorias\n",
    "category_counts = Counter(job_categories.values())\n",
    "\n",
    "print(f\"✅ Classificação concluída!\")\n",
    "print(f\"📊 Categorias identificadas: {len(category_counts)}\")\n",
    "\n",
    "print(\"\\n📈 Distribuição por Categoria:\")\n",
    "for category, count in category_counts.most_common():\n",
    "    percentage = (count / len(job_categories)) * 100\n",
    "    print(f\"{category:<20} {count:3d} ofertas ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗺️ 5. Análise Geográfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar distribuição geográfica\n",
    "print(\"🗺️ Analisando distribuição geográfica...\")\n",
    "location_data = analyzer.analyze_locations()\n",
    "\n",
    "print(f\"✅ Análise geográfica concluída!\")\n",
    "print(f\"🏙️ Cidades com ofertas: {location_data['total_locations']}\")\n",
    "\n",
    "print(\"\\n🏆 Top 10 Cidades:\")\n",
    "for i, (city, count) in enumerate(list(location_data['top_locations'].items())[:10], 1):\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{i:2d}. {city:<20} {count:3d} ofertas ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 6. Análise de Embeddings e Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar embeddings para skills\n",
    "print(\"🧠 Gerando embeddings para skills...\")\n",
    "skill_embeddings = analyzer.generate_embeddings_for_skills()\n",
    "\n",
    "if len(skill_embeddings) > 0:\n",
    "    print(f\"✅ Embeddings gerados para {len(skill_embeddings)} skills\")\n",
    "    \n",
    "    # Executar clustering\n",
    "    print(\"🔄 Executando clustering de skills...\")\n",
    "    skill_clusters = analyzer.cluster_skills(n_clusters=6)\n",
    "    \n",
    "    print(f\"✅ Clustering concluído! {len(skill_clusters)} clusters criados\")\n",
    "    \n",
    "    print(\"\\n🎯 Clusters de Skills:\")\n",
    "    for cluster_id, skills in skill_clusters.items():\n",
    "        print(f\"\\nCluster {cluster_id + 1}: {', '.join(skills[:8])}\")\n",
    "        if len(skills) > 8:\n",
    "            print(f\"           ... e mais {len(skills) - 8} skills\")\n",
    "else:\n",
    "    print(\"⚠️ Não foi possível gerar embeddings suficientes\")\n",
    "    skill_clusters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 7. Skills por Categoria de Emprego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar skills por categoria\n",
    "print(\"📊 Analisando skills por categoria de emprego...\")\n",
    "category_skills = analyzer.get_top_skills_by_category()\n",
    "\n",
    "print(f\"✅ Análise concluída para {len(category_skills)} categorias\")\n",
    "\n",
    "print(\"\\n🎯 Top Skills por Categoria:\")\n",
    "for category, skills in category_skills.items():\n",
    "    if skills:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for i, (skill, count) in enumerate(skills[:5], 1):\n",
    "            print(f\"  {i}. {skill} ({count} menções)\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: Sem dados suficientes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 8. Análise de Tendências Avançada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar analisador de tendências\n",
    "print(\"📈 Inicializando análise de tendências...\")\n",
    "trend_analyzer = TrendAnalyzer(analyzer)\n",
    "\n",
    "# Analisar complexidade dos requisitos\n",
    "print(\"🔍 Analisando complexidade dos requisitos...\")\n",
    "complexity_analysis = trend_analyzer.analyze_job_requirements_complexity()\n",
    "\n",
    "print(f\"✅ Análise de complexidade concluída!\")\n",
    "print(f\"📊 Score médio de complexidade: {complexity_analysis['avg_complexity']:.1f}\")\n",
    "\n",
    "print(\"\\n👔 Distribuição por Nível de Experiência:\")\n",
    "for level, count in complexity_analysis['experience_distribution'].items():\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{level:<15} {count:3d} ofertas ({percentage:5.1f}%)\")\n",
    "\n",
    "print(\"\\n🎓 Distribuição por Nível Educacional:\")\n",
    "for level, count in complexity_analysis['education_distribution'].items():\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{level:<15} {count:3d} ofertas ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar skills emergentes\n",
    "print(\"🚀 Detectando skills emergentes...\")\n",
    "emerging_analysis = trend_analyzer.detect_emerging_skills()\n",
    "\n",
    "print(f\"✅ Análise de skills emergentes concluída!\")\n",
    "\n",
    "if emerging_analysis.get('emerging_skills'):\n",
    "    print(\"\\n🌟 Skills Emergentes:\")\n",
    "    for skill, count in emerging_analysis['emerging_skills'][:10]:\n",
    "        print(f\"• {skill} ({count} menções)\")\n",
    "\n",
    "if emerging_analysis.get('top_skill_combinations'):\n",
    "    print(\"\\n🔗 Combinações de Skills Mais Comuns:\")\n",
    "    for skill1, skill2, count in emerging_analysis['top_skill_combinations'][:8]:\n",
    "        print(f\"• {skill1} + {skill2} ({count} co-ocorrências)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de saturação do mercado\n",
    "print(\"📊 Analisando saturação do mercado...\")\n",
    "saturation_analysis = trend_analyzer.analyze_market_saturation()\n",
    "\n",
    "print(f\"✅ Análise de saturação concluída!\")\n",
    "\n",
    "print(\"\\n📈 Saturação por Categoria:\")\n",
    "for category, data in saturation_analysis['category_saturation'].items():\n",
    "    print(f\"{category:<20} {data['percentage']:5.1f}% - {data['saturation_level']}\")\n",
    "\n",
    "print(\"\\n🏙️ Saturação por Localização:\")\n",
    "for location, data in list(saturation_analysis['location_saturation'].items())[:8]:\n",
    "    print(f\"{location:<20} {data['percentage']:5.1f}% - {data['saturation_level']}\")\n",
    "\n",
    "concentration = saturation_analysis['market_concentration']\n",
    "print(f\"\\n🎯 Concentração do Mercado:\")\n",
    "print(f\"• Principal categoria: {concentration['top_category_share']:.1f}% do mercado\")\n",
    "print(f\"• Principal localização: {concentration['top_location_share']:.1f}% do mercado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 9. Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar engine de visualização\n",
    "print(\"🎨 Inicializando visualizações...\")\n",
    "viz_engine = VisualizationEngine()\n",
    "\n",
    "# Visualizar distribuição geográfica\n",
    "print(\"🗺️ Criando visualização geográfica...\")\n",
    "viz_engine.plot_location_distribution(location_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar categorias de emprego\n",
    "print(\"💼 Criando visualização de categorias...\")\n",
    "viz_engine.plot_job_categories(job_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar skills por categoria\n",
    "print(\"🎯 Criando visualização de skills por categoria...\")\n",
    "viz_engine.plot_skills_by_category(category_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar clusters de skills\n",
    "if skill_clusters:\n",
    "    print(\"🧠 Criando visualização de clusters...\")\n",
    "    viz_engine.plot_skill_clusters(skill_clusters)\n",
    "else:\n",
    "    print(\"⚠️ Sem clusters para visualizar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar wordcloud das skills\n",
    "print(\"☁️ Criando wordcloud das skills...\")\n",
    "viz_engine.create_skills_wordcloud(analyzer.all_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📱 10. Dashboard Interativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dashboard interativo\n",
    "print(\"📱 Criando dashboard interativo...\")\n",
    "viz_engine.create_interactive_dashboard(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 11. Análises Avançadas com HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling\n",
    "print(\"📚 Executando topic modeling...\")\n",
    "topics_analysis = trend_analyzer.topic_modeling_jobs(n_topics=6)\n",
    "\n",
    "if topics_analysis:\n",
    "    print(f\"✅ Topic modeling concluído!\")\n",
    "    print(f\"📊 {len(topics_analysis['topics'])} tópicos identificados\")\n",
    "    print(f\"📄 {topics_analysis['n_documents']} documentos analisados\")\n",
    "    \n",
    "    print(\"\\n📚 Tópicos Descobertos:\")\n",
    "    for topic_name, topic_data in topics_analysis['topics'].items():\n",
    "        words = ', '.join(topic_data['words'][:6])\n",
    "        print(f\"{topic_name}: {words}\")\n",
    "    \n",
    "    print(\"\\n📈 Distribuição dos Tópicos:\")\n",
    "    for topic, count in topics_analysis['topic_distribution'].most_common():\n",
    "        percentage = (count / topics_analysis['n_documents']) * 100\n",
    "        print(f\"{topic}: {count} documentos ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"⚠️ Topic modeling não foi executado devido a dados insuficientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de sentimento\n",
    "print(\"😊 Executando análise de sentimento...\")\n",
    "sentiment_analysis = trend_analyzer.analyze_job_posting_sentiment()\n",
    "\n",
    "print(f\"✅ Análise de sentimento concluída!\")\n",
    "print(f\"📊 Score médio de sentimento: {sentiment_analysis['avg_sentiment_score']:.3f}\")\n",
    "\n",
    "print(\"\\n😊 Distribuição Geral de Sentimento:\")\n",
    "for sentiment, count in sentiment_analysis['overall_sentiment'].items():\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{sentiment:<10} {count:3d} ofertas ({percentage:5.1f}%)\")\n",
    "\n",
    "print(\"\\n📊 Sentimento por Categoria:\")\n",
    "for category, sentiments in sentiment_analysis['sentiment_by_category'].items():\n",
    "    if sentiments:\n",
    "        most_common = sentiments.most_common(1)[0]\n",
    "        print(f\"{category:<20} Predominante: {most_common[0]} ({most_common[1]} ofertas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 12. Recomendações Personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar recomendações gerais\n",
    "print(\"💡 Gerando recomendações de skills...\")\n",
    "recommendations = trend_analyzer.generate_skill_recommendations()\n",
    "\n",
    "print(f\"✅ Recomendações geradas para {len(recommendations)} categorias!\")\n",
    "\n",
    "print(\"\\n🎯 Recomendações por Categoria:\")\n",
    "for category, data in recommendations.items():\n",
    "    if 'top_skills' in data:\n",
    "        skills = ', '.join(data['top_skills'][:5])\n",
    "        print(f\"\\n{category}:\")\n",
    "        print(f\"  • Skills principais: {skills}\")\n",
    "        print(f\"  • Demanda no mercado: {data['market_demand']} ofertas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendações específicas para Software Development\n",
    "print(\"💻 Recomendações específicas para Software Development...\")\n",
    "sw_recommendations = trend_analyzer.generate_skill_recommendations('Software Development')\n",
    "\n",
    "if 'Software Development' in sw_recommendations:\n",
    "    sw_data = sw_recommendations['Software Development']\n",
    "    \n",
    "    print(\"\\n🔧 Skills Fundamentais:\")\n",
    "    for skill in sw_data.get('core_skills', [])[:8]:\n",
    "        print(f\"  • {skill}\")\n",
    "    \n",
    "    if sw_data.get('emerging_skills'):\n",
    "        print(\"\\n🌟 Skills Emergentes:\")\n",
    "        for skill in sw_data['emerging_skills'][:5]:\n",
    "            print(f\"  • {skill}\")\n",
    "    \n",
    "    if sw_data.get('skill_combinations'):\n",
    "        print(\"\\n🔗 Combinações Recomendadas:\")\n",
    "        for combo in sw_data['skill_combinations'][:5]:\n",
    "            print(f\"  • {combo}\")\n",
    "else:\n",
    "    print(\"⚠️ Dados insuficientes para recomendações específicas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 13. Relatório Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relatório final\n",
    "print(\"📋 Gerando relatório final...\")\n",
    "final_report = viz_engine.generate_summary_report(analyzer)\n",
    "\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 14. Insights e Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights finais baseados na análise\n",
    "print(\"🎯 INSIGHTS PRINCIPAIS DA ANÁLISE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Top city\n",
    "top_city = list(location_data['top_locations'].keys())[0]\n",
    "top_city_percentage = (list(location_data['top_locations'].values())[0] / len(analyzer.df)) * 100\n",
    "\n",
    "# Top category\n",
    "top_category = category_counts.most_common(1)[0]\n",
    "\n",
    "# Top skill\n",
    "top_skill = skill_counts.most_common(1)[0]\n",
    "\n",
    "print(f\"🏙️ CONCENTRAÇÃO GEOGRÁFICA:\")\n",
    "print(f\"   • {top_city} domina com {top_city_percentage:.1f}% das ofertas\")\n",
    "print(f\"   • Sugere centralização do mercado de trabalho\")\n",
    "\n",
    "print(f\"\\n💼 DEMANDA POR CATEGORIAS:\")\n",
    "print(f\"   • {top_category[0]} é a categoria mais demandada ({top_category[1]} ofertas)\")\n",
    "print(f\"   • Representa {(top_category[1]/len(analyzer.df)*100):.1f}% do mercado\")\n",
    "\n",
    "print(f\"\\n🎯 SKILLS EM DESTAQUE:\")\n",
    "print(f\"   • {top_skill[0]} é a skill mais procurada ({top_skill[1]} menções)\")\n",
    "print(f\"   • Skills técnicas dominam o mercado\")\n",
    "\n",
    "if complexity_analysis:\n",
    "    exp_dist = complexity_analysis['experience_distribution']\n",
    "    most_common_exp = exp_dist.most_common(1)[0]\n",
    "    print(f\"\\n👔 NÍVEL DE EXPERIÊNCIA:\")\n",
    "    print(f\"   • {most_common_exp[0]} é o nível mais procurado ({most_common_exp[1]} ofertas)\")\n",
    "    print(f\"   • Score médio de complexidade: {complexity_analysis['avg_complexity']:.1f}\")\n",
    "\n",
    "if sentiment_analysis:\n",
    "    dominant_sentiment = sentiment_analysis['overall_sentiment'].most_common(1)[0]\n",
    "    print(f\"\\n😊 SENTIMENTO DAS OFERTAS:\")\n",
    "    print(f\"   • Sentimento predominante: {dominant_sentiment[0]} ({dominant_sentiment[1]} ofertas)\")\n",
    "    print(f\"   • Score médio: {sentiment_analysis['avg_sentiment_score']:.3f}\")\n",
    "\n",
    "print(f\"\\n🚀 RECOMENDAÇÕES ESTRATÉGICAS:\")\n",
    "print(f\"   • Foque em skills técnicas modernas (AI, Cloud, DevOps)\")\n",
    "print(f\"   • Considere oportunidades fora de {top_city} para menor competição\")\n",
    "print(f\"   • Desenvolva competências em {top_category[0].lower()}\")\n",
    "print(f\"   • Combine skills complementares para se destacar\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"✅ ANÁLISE COMPLETA FINALIZADA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 15. Exportar Resultados (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados em arquivos\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Criar timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Salvar dados processados\n",
    "analyzer.df.to_csv(f'processed_jobs_{timestamp}.csv', index=False)\n",
    "\n",
    "# Salvar resultados da análise\n",
    "results = {\n",
    "    'location_analysis': location_data,\n",
    "    'category_distribution': dict(category_counts),\n",
    "    'top_skills': dict(skill_counts.most_common(50)),\n",
    "    'skills_by_category': {k: v[:10] for k, v in category_skills.items()},\n",
    "    'analysis_metadata': {\n",
    "        'total_jobs': len(analyzer.df),\n",
    "        'unique_skills': len(set(analyzer.all_skills)),\n",
    "        'cities_count': len(location_data['raw_counts']),\n",
    "        'categories_count': len(category_counts),\n",
    "        'analysis_date': timestamp\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'analysis_results_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Salvar relatório\n",
    "with open(f'market_report_{timestamp}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "print(f\"💾 Resultados salvos com timestamp: {timestamp}\")\n",
    "print(f\"📊 Arquivo de dados: processed_jobs_{timestamp}.csv\")\n",
    "print(f\"📋 Arquivo de resultados: analysis_results_{timestamp}.json\")\n",
    "print(f\"📄 Relatório: market_report_{timestamp}.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
