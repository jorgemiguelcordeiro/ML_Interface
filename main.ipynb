{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ AnÃ¡lise AvanÃ§ada do Mercado de Trabalho em Portugal\n",
    "\n",
    "Este notebook realiza uma anÃ¡lise completa das ofertas de emprego usando modelos da Hugging Face e tÃ©cnicas avanÃ§adas de NLP.\n",
    "\n",
    "## ğŸ“Š Funcionalidades:\n",
    "- ExtraÃ§Ã£o inteligente de skills usando NER\n",
    "- ClassificaÃ§Ã£o automÃ¡tica de tipos de emprego\n",
    "- AnÃ¡lise de sentimento das ofertas\n",
    "- Topic modeling para descobrir tendÃªncias\n",
    "- Clustering de skills similares\n",
    "- VisualizaÃ§Ãµes interativas\n",
    "- RecomendaÃ§Ãµes personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstalaÃ§Ã£o de dependÃªncias (execute apenas uma vez)\n",
    "!pip install transformers torch pandas numpy matplotlib seaborn plotly wordcloud\n",
    "!pip install scikit-learn networkx sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from job_analyzer import JobAnalyzer\n",
    "from visualization_engine import VisualizationEngine\n",
    "from trend_analyzer import TrendAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ConfiguraÃ§Ãµes\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"âœ… Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 1. InicializaÃ§Ã£o e Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o analisador\n",
    "print(\"ğŸ”„ Inicializando JobAnalyzer...\")\n",
    "analyzer = JobAnalyzer('expresso_empregos + pequeno.csv')\n",
    "\n",
    "print(f\"ğŸ“Š Dados carregados: {len(analyzer.df)} ofertas de emprego\")\n",
    "print(f\"ğŸ“… PerÃ­odo: {analyzer.df['post_date'].min()} a {analyzer.df['post_date'].max()}\")\n",
    "\n",
    "# Visualizar amostra dos dados\n",
    "print(\"\\nğŸ” Amostra dos dados:\")\n",
    "analyzer.df[['title', 'location', 'recruiter']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ 2. Preprocessamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar e preprocessar dados\n",
    "print(\"ğŸ§¹ Executando preprocessamento...\")\n",
    "processed_data = analyzer.clean_and_preprocess()\n",
    "\n",
    "print(f\"âœ… Preprocessamento concluÃ­do!\")\n",
    "print(f\"ğŸ“Š Dados finais: {len(processed_data)} ofertas\")\n",
    "print(f\"ğŸ“ MÃ©dia de palavras por oferta: {processed_data['word_count'].mean():.0f}\")\n",
    "print(f\"ğŸ“ MÃ©dia de caracteres por oferta: {processed_data['text_length'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 3. ExtraÃ§Ã£o de Skills com Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair skills usando modelos HF\n",
    "print(\"ğŸ¯ Extraindo skills com modelos da Hugging Face...\")\n",
    "skills_by_job = analyzer.extract_skills_with_hf()\n",
    "\n",
    "# EstatÃ­sticas das skills\n",
    "total_skills = len(analyzer.all_skills)\n",
    "unique_skills = len(set(analyzer.all_skills))\n",
    "avg_skills_per_job = np.mean([len(skills) for skills in skills_by_job.values()])\n",
    "\n",
    "print(f\"âœ… ExtraÃ§Ã£o concluÃ­da!\")\n",
    "print(f\"ğŸ” Total de skills encontradas: {total_skills}\")\n",
    "print(f\"ğŸ¯ Skills Ãºnicas: {unique_skills}\")\n",
    "print(f\"ğŸ“Š MÃ©dia de skills por oferta: {avg_skills_per_job:.1f}\")\n",
    "\n",
    "# Top 15 skills mais procuradas\n",
    "from collections import Counter\n",
    "skill_counts = Counter(analyzer.all_skills)\n",
    "print(\"\\nğŸ† Top 15 Skills Mais Procuradas:\")\n",
    "for i, (skill, count) in enumerate(skill_counts.most_common(15), 1):\n",
    "    print(f\"{i:2d}. {skill:<25} ({count} menÃ§Ãµes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¢ 4. ClassificaÃ§Ã£o de Tipos de Emprego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificar tipos de emprego\n",
    "print(\"ğŸ¢ Classificando tipos de emprego...\")\n",
    "job_categories = analyzer.classify_job_types_with_hf()\n",
    "\n",
    "# EstatÃ­sticas das categorias\n",
    "category_counts = Counter(job_categories.values())\n",
    "\n",
    "print(f\"âœ… ClassificaÃ§Ã£o concluÃ­da!\")\n",
    "print(f\"ğŸ“Š Categorias identificadas: {len(category_counts)}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ DistribuiÃ§Ã£o por Categoria:\")\n",
    "for category, count in category_counts.most_common():\n",
    "    percentage = (count / len(job_categories)) * 100\n",
    "    print(f\"{category:<20} {count:3d} ofertas ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ 5. AnÃ¡lise GeogrÃ¡fica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar distribuiÃ§Ã£o geogrÃ¡fica\n",
    "print(\"ğŸ—ºï¸ Analisando distribuiÃ§Ã£o geogrÃ¡fica...\")\n",
    "location_data = analyzer.analyze_locations()\n",
    "\n",
    "print(f\"âœ… AnÃ¡lise geogrÃ¡fica concluÃ­da!\")\n",
    "print(f\"ğŸ™ï¸ Cidades com ofertas: {location_data['total_locations']}\")\n",
    "\n",
    "print(\"\\nğŸ† Top 10 Cidades:\")\n",
    "for i, (city, count) in enumerate(list(location_data['top_locations'].items())[:10], 1):\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{i:2d}. {city:<20} {count:3d} ofertas ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  6. AnÃ¡lise de Embeddings e Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar embeddings para skills\n",
    "print(\"ğŸ§  Gerando embeddings para skills...\")\n",
    "skill_embeddings = analyzer.generate_embeddings_for_skills()\n",
    "\n",
    "if len(skill_embeddings) > 0:\n",
    "    print(f\"âœ… Embeddings gerados para {len(skill_embeddings)} skills\")\n",
    "    \n",
    "    # Executar clustering\n",
    "    print(\"ğŸ”„ Executando clustering de skills...\")\n",
    "    skill_clusters = analyzer.cluster_skills(n_clusters=6)\n",
    "    \n",
    "    print(f\"âœ… Clustering concluÃ­do! {len(skill_clusters)} clusters criados\")\n",
    "    \n",
    "    print(\"\\nğŸ¯ Clusters de Skills:\")\n",
    "    for cluster_id, skills in skill_clusters.items():\n",
    "        print(f\"\\nCluster {cluster_id + 1}: {', '.join(skills[:8])}\")\n",
    "        if len(skills) > 8:\n",
    "            print(f\"           ... e mais {len(skills) - 8} skills\")\n",
    "else:\n",
    "    print(\"âš ï¸ NÃ£o foi possÃ­vel gerar embeddings suficientes\")\n",
    "    skill_clusters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 7. Skills por Categoria de Emprego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar skills por categoria\n",
    "print(\"ğŸ“Š Analisando skills por categoria de emprego...\")\n",
    "category_skills = analyzer.get_top_skills_by_category()\n",
    "\n",
    "print(f\"âœ… AnÃ¡lise concluÃ­da para {len(category_skills)} categorias\")\n",
    "\n",
    "print(\"\\nğŸ¯ Top Skills por Categoria:\")\n",
    "for category, skills in category_skills.items():\n",
    "    if skills:\n",
    "        print(f\"\\n{category}:\")\n",
    "        for i, (skill, count) in enumerate(skills[:5], 1):\n",
    "            print(f\"  {i}. {skill} ({count} menÃ§Ãµes)\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: Sem dados suficientes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 8. AnÃ¡lise de TendÃªncias AvanÃ§ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar analisador de tendÃªncias\n",
    "print(\"ğŸ“ˆ Inicializando anÃ¡lise de tendÃªncias...\")\n",
    "trend_analyzer = TrendAnalyzer(analyzer)\n",
    "\n",
    "# Analisar complexidade dos requisitos\n",
    "print(\"ğŸ” Analisando complexidade dos requisitos...\")\n",
    "complexity_analysis = trend_analyzer.analyze_job_requirements_complexity()\n",
    "\n",
    "print(f\"âœ… AnÃ¡lise de complexidade concluÃ­da!\")\n",
    "print(f\"ğŸ“Š Score mÃ©dio de complexidade: {complexity_analysis['avg_complexity']:.1f}\")\n",
    "\n",
    "print(\"\\nğŸ‘” DistribuiÃ§Ã£o por NÃ­vel de ExperiÃªncia:\")\n",
    "for level, count in complexity_analysis['experience_distribution'].items():\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{level:<15} {count:3d} ofertas ({percentage:5.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ“ DistribuiÃ§Ã£o por NÃ­vel Educacional:\")\n",
    "for level, count in complexity_analysis['education_distribution'].items():\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{level:<15} {count:3d} ofertas ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar skills emergentes\n",
    "print(\"ğŸš€ Detectando skills emergentes...\")\n",
    "emerging_analysis = trend_analyzer.detect_emerging_skills()\n",
    "\n",
    "print(f\"âœ… AnÃ¡lise de skills emergentes concluÃ­da!\")\n",
    "\n",
    "if emerging_analysis.get('emerging_skills'):\n",
    "    print(\"\\nğŸŒŸ Skills Emergentes:\")\n",
    "    for skill, count in emerging_analysis['emerging_skills'][:10]:\n",
    "        print(f\"â€¢ {skill} ({count} menÃ§Ãµes)\")\n",
    "\n",
    "if emerging_analysis.get('top_skill_combinations'):\n",
    "    print(\"\\nğŸ”— CombinaÃ§Ãµes de Skills Mais Comuns:\")\n",
    "    for skill1, skill2, count in emerging_analysis['top_skill_combinations'][:8]:\n",
    "        print(f\"â€¢ {skill1} + {skill2} ({count} co-ocorrÃªncias)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise de saturaÃ§Ã£o do mercado\n",
    "print(\"ğŸ“Š Analisando saturaÃ§Ã£o do mercado...\")\n",
    "saturation_analysis = trend_analyzer.analyze_market_saturation()\n",
    "\n",
    "print(f\"âœ… AnÃ¡lise de saturaÃ§Ã£o concluÃ­da!\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ SaturaÃ§Ã£o por Categoria:\")\n",
    "for category, data in saturation_analysis['category_saturation'].items():\n",
    "    print(f\"{category:<20} {data['percentage']:5.1f}% - {data['saturation_level']}\")\n",
    "\n",
    "print(\"\\nğŸ™ï¸ SaturaÃ§Ã£o por LocalizaÃ§Ã£o:\")\n",
    "for location, data in list(saturation_analysis['location_saturation'].items())[:8]:\n",
    "    print(f\"{location:<20} {data['percentage']:5.1f}% - {data['saturation_level']}\")\n",
    "\n",
    "concentration = saturation_analysis['market_concentration']\n",
    "print(f\"\\nğŸ¯ ConcentraÃ§Ã£o do Mercado:\")\n",
    "print(f\"â€¢ Principal categoria: {concentration['top_category_share']:.1f}% do mercado\")\n",
    "print(f\"â€¢ Principal localizaÃ§Ã£o: {concentration['top_location_share']:.1f}% do mercado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ 9. VisualizaÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar engine de visualizaÃ§Ã£o\n",
    "print(\"ğŸ¨ Inicializando visualizaÃ§Ãµes...\")\n",
    "viz_engine = VisualizationEngine()\n",
    "\n",
    "# Visualizar distribuiÃ§Ã£o geogrÃ¡fica\n",
    "print(\"ğŸ—ºï¸ Criando visualizaÃ§Ã£o geogrÃ¡fica...\")\n",
    "viz_engine.plot_location_distribution(location_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar categorias de emprego\n",
    "print(\"ğŸ’¼ Criando visualizaÃ§Ã£o de categorias...\")\n",
    "viz_engine.plot_job_categories(job_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar skills por categoria\n",
    "print(\"ğŸ¯ Criando visualizaÃ§Ã£o de skills por categoria...\")\n",
    "viz_engine.plot_skills_by_category(category_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar clusters de skills\n",
    "if skill_clusters:\n",
    "    print(\"ğŸ§  Criando visualizaÃ§Ã£o de clusters...\")\n",
    "    viz_engine.plot_skill_clusters(skill_clusters)\n",
    "else:\n",
    "    print(\"âš ï¸ Sem clusters para visualizar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar wordcloud das skills\n",
    "print(\"â˜ï¸ Criando wordcloud das skills...\")\n",
    "viz_engine.create_skills_wordcloud(analyzer.all_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“± 10. Dashboard Interativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dashboard interativo\n",
    "print(\"ğŸ“± Criando dashboard interativo...\")\n",
    "viz_engine.create_interactive_dashboard(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– 11. AnÃ¡lises AvanÃ§adas com HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling\n",
    "print(\"ğŸ“š Executando topic modeling...\")\n",
    "topics_analysis = trend_analyzer.topic_modeling_jobs(n_topics=6)\n",
    "\n",
    "if topics_analysis:\n",
    "    print(f\"âœ… Topic modeling concluÃ­do!\")\n",
    "    print(f\"ğŸ“Š {len(topics_analysis['topics'])} tÃ³picos identificados\")\n",
    "    print(f\"ğŸ“„ {topics_analysis['n_documents']} documentos analisados\")\n",
    "    \n",
    "    print(\"\\nğŸ“š TÃ³picos Descobertos:\")\n",
    "    for topic_name, topic_data in topics_analysis['topics'].items():\n",
    "        words = ', '.join(topic_data['words'][:6])\n",
    "        print(f\"{topic_name}: {words}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ DistribuiÃ§Ã£o dos TÃ³picos:\")\n",
    "    for topic, count in topics_analysis['topic_distribution'].most_common():\n",
    "        percentage = (count / topics_analysis['n_documents']) * 100\n",
    "        print(f\"{topic}: {count} documentos ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"âš ï¸ Topic modeling nÃ£o foi executado devido a dados insuficientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise de sentimento\n",
    "print(\"ğŸ˜Š Executando anÃ¡lise de sentimento...\")\n",
    "sentiment_analysis = trend_analyzer.analyze_job_posting_sentiment()\n",
    "\n",
    "print(f\"âœ… AnÃ¡lise de sentimento concluÃ­da!\")\n",
    "print(f\"ğŸ“Š Score mÃ©dio de sentimento: {sentiment_analysis['avg_sentiment_score']:.3f}\")\n",
    "\n",
    "print(\"\\nğŸ˜Š DistribuiÃ§Ã£o Geral de Sentimento:\")\n",
    "for sentiment, count in sentiment_analysis['overall_sentiment'].items():\n",
    "    percentage = (count / len(analyzer.df)) * 100\n",
    "    print(f\"{sentiment:<10} {count:3d} ofertas ({percentage:5.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ“Š Sentimento por Categoria:\")\n",
    "for category, sentiments in sentiment_analysis['sentiment_by_category'].items():\n",
    "    if sentiments:\n",
    "        most_common = sentiments.most_common(1)[0]\n",
    "        print(f\"{category:<20} Predominante: {most_common[0]} ({most_common[1]} ofertas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ 12. RecomendaÃ§Ãµes Personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar recomendaÃ§Ãµes gerais\n",
    "print(\"ğŸ’¡ Gerando recomendaÃ§Ãµes de skills...\")\n",
    "recommendations = trend_analyzer.generate_skill_recommendations()\n",
    "\n",
    "print(f\"âœ… RecomendaÃ§Ãµes geradas para {len(recommendations)} categorias!\")\n",
    "\n",
    "print(\"\\nğŸ¯ RecomendaÃ§Ãµes por Categoria:\")\n",
    "for category, data in recommendations.items():\n",
    "    if 'top_skills' in data:\n",
    "        skills = ', '.join(data['top_skills'][:5])\n",
    "        print(f\"\\n{category}:\")\n",
    "        print(f\"  â€¢ Skills principais: {skills}\")\n",
    "        print(f\"  â€¢ Demanda no mercado: {data['market_demand']} ofertas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecomendaÃ§Ãµes especÃ­ficas para Software Development\n",
    "print(\"ğŸ’» RecomendaÃ§Ãµes especÃ­ficas para Software Development...\")\n",
    "sw_recommendations = trend_analyzer.generate_skill_recommendations('Software Development')\n",
    "\n",
    "if 'Software Development' in sw_recommendations:\n",
    "    sw_data = sw_recommendations['Software Development']\n",
    "    \n",
    "    print(\"\\nğŸ”§ Skills Fundamentais:\")\n",
    "    for skill in sw_data.get('core_skills', [])[:8]:\n",
    "        print(f\"  â€¢ {skill}\")\n",
    "    \n",
    "    if sw_data.get('emerging_skills'):\n",
    "        print(\"\\nğŸŒŸ Skills Emergentes:\")\n",
    "        for skill in sw_data['emerging_skills'][:5]:\n",
    "            print(f\"  â€¢ {skill}\")\n",
    "    \n",
    "    if sw_data.get('skill_combinations'):\n",
    "        print(\"\\nğŸ”— CombinaÃ§Ãµes Recomendadas:\")\n",
    "        for combo in sw_data['skill_combinations'][:5]:\n",
    "            print(f\"  â€¢ {combo}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Dados insuficientes para recomendaÃ§Ãµes especÃ­ficas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ 13. RelatÃ³rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relatÃ³rio final\n",
    "print(\"ğŸ“‹ Gerando relatÃ³rio final...\")\n",
    "final_report = viz_engine.generate_summary_report(analyzer)\n",
    "\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 14. Insights e ConclusÃµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights finais baseados na anÃ¡lise\n",
    "print(\"ğŸ¯ INSIGHTS PRINCIPAIS DA ANÃLISE:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Top city\n",
    "top_city = list(location_data['top_locations'].keys())[0]\n",
    "top_city_percentage = (list(location_data['top_locations'].values())[0] / len(analyzer.df)) * 100\n",
    "\n",
    "# Top category\n",
    "top_category = category_counts.most_common(1)[0]\n",
    "\n",
    "# Top skill\n",
    "top_skill = skill_counts.most_common(1)[0]\n",
    "\n",
    "print(f\"ğŸ™ï¸ CONCENTRAÃ‡ÃƒO GEOGRÃFICA:\")\n",
    "print(f\"   â€¢ {top_city} domina com {top_city_percentage:.1f}% das ofertas\")\n",
    "print(f\"   â€¢ Sugere centralizaÃ§Ã£o do mercado de trabalho\")\n",
    "\n",
    "print(f\"\\nğŸ’¼ DEMANDA POR CATEGORIAS:\")\n",
    "print(f\"   â€¢ {top_category[0]} Ã© a categoria mais demandada ({top_category[1]} ofertas)\")\n",
    "print(f\"   â€¢ Representa {(top_category[1]/len(analyzer.df)*100):.1f}% do mercado\")\n",
    "\n",
    "print(f\"\\nğŸ¯ SKILLS EM DESTAQUE:\")\n",
    "print(f\"   â€¢ {top_skill[0]} Ã© a skill mais procurada ({top_skill[1]} menÃ§Ãµes)\")\n",
    "print(f\"   â€¢ Skills tÃ©cnicas dominam o mercado\")\n",
    "\n",
    "if complexity_analysis:\n",
    "    exp_dist = complexity_analysis['experience_distribution']\n",
    "    most_common_exp = exp_dist.most_common(1)[0]\n",
    "    print(f\"\\nğŸ‘” NÃVEL DE EXPERIÃŠNCIA:\")\n",
    "    print(f\"   â€¢ {most_common_exp[0]} Ã© o nÃ­vel mais procurado ({most_common_exp[1]} ofertas)\")\n",
    "    print(f\"   â€¢ Score mÃ©dio de complexidade: {complexity_analysis['avg_complexity']:.1f}\")\n",
    "\n",
    "if sentiment_analysis:\n",
    "    dominant_sentiment = sentiment_analysis['overall_sentiment'].most_common(1)[0]\n",
    "    print(f\"\\nğŸ˜Š SENTIMENTO DAS OFERTAS:\")\n",
    "    print(f\"   â€¢ Sentimento predominante: {dominant_sentiment[0]} ({dominant_sentiment[1]} ofertas)\")\n",
    "    print(f\"   â€¢ Score mÃ©dio: {sentiment_analysis['avg_sentiment_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸš€ RECOMENDAÃ‡Ã•ES ESTRATÃ‰GICAS:\")\n",
    "print(f\"   â€¢ Foque em skills tÃ©cnicas modernas (AI, Cloud, DevOps)\")\n",
    "print(f\"   â€¢ Considere oportunidades fora de {top_city} para menor competiÃ§Ã£o\")\n",
    "print(f\"   â€¢ Desenvolva competÃªncias em {top_category[0].lower()}\")\n",
    "print(f\"   â€¢ Combine skills complementares para se destacar\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"âœ… ANÃLISE COMPLETA FINALIZADA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 15. Exportar Resultados (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados em arquivos\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Criar timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Salvar dados processados\n",
    "analyzer.df.to_csv(f'processed_jobs_{timestamp}.csv', index=False)\n",
    "\n",
    "# Salvar resultados da anÃ¡lise\n",
    "results = {\n",
    "    'location_analysis': location_data,\n",
    "    'category_distribution': dict(category_counts),\n",
    "    'top_skills': dict(skill_counts.most_common(50)),\n",
    "    'skills_by_category': {k: v[:10] for k, v in category_skills.items()},\n",
    "    'analysis_metadata': {\n",
    "        'total_jobs': len(analyzer.df),\n",
    "        'unique_skills': len(set(analyzer.all_skills)),\n",
    "        'cities_count': len(location_data['raw_counts']),\n",
    "        'categories_count': len(category_counts),\n",
    "        'analysis_date': timestamp\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'analysis_results_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Salvar relatÃ³rio\n",
    "with open(f'market_report_{timestamp}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "print(f\"ğŸ’¾ Resultados salvos com timestamp: {timestamp}\")\n",
    "print(f\"ğŸ“Š Arquivo de dados: processed_jobs_{timestamp}.csv\")\n",
    "print(f\"ğŸ“‹ Arquivo de resultados: analysis_results_{timestamp}.json\")\n",
    "print(f\"ğŸ“„ RelatÃ³rio: market_report_{timestamp}.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
